{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASDF from scratch\n",
    "The tutorial for `pyasdf` at http://seismicdata.github.io/pyasdf/tutorial.html is a great starting point for general seismic analysis, i.e. assuming you have QuakeML and StationXML files ready to be assimilated into ASDF. My lab EQ data is all raw and messy, so I'll need to start out by creating these sub-structures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StationXML for the lab\n",
    "I'll follow this ObsPy tutorial on __[creating a StationXML file from scratch](https://docs.obspy.org/tutorial/code_snippets/stationxml_file_from_scratch.html)__.\n",
    "\n",
    "The lab sensor network is named the Glaser Lab Nano-Network (GLNN or GL) here, for local purposes only. This will fit into a file hierarchy of **Inventory > Network > Station > Channel**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import obspy\n",
    "from obspy.core.inventory import Inventory, Network, Station, Channel, Site\n",
    "from obspy.clients.nrl import NRL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the hierarchy levels is an object that needs to be created. For now, I'm following the tutorial exactly rather than starting to incorporate real info about the GLNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv = Inventory(\n",
    "    # We'll add networks later.\n",
    "    networks=[],\n",
    "    # The source should be the id of whoever creates the file.\n",
    "    source=\"ObsPy-Tutorial\")\n",
    "\n",
    "net = Network(\n",
    "    # This is the network code according to the SEED standard.\n",
    "    code=\"XX\",\n",
    "    # A list of stations. We'll add one later.\n",
    "    stations=[],\n",
    "    description=\"A test of stations.\",\n",
    "    # Start and end dates are optional.\n",
    "    start_date=obspy.UTCDateTime(2016, 1, 2))\n",
    "\n",
    "sta = Station(\n",
    "    # This is the station code according to the SEED standard.\n",
    "    code=\"ABC\",\n",
    "    latitude=1.0,\n",
    "    longitude=2.0,\n",
    "    elevation=345.0,\n",
    "    creation_date=obspy.UTCDateTime(2016, 1, 2),\n",
    "    site=Site(name=\"First station\"))\n",
    "\n",
    "cha = Channel(\n",
    "    # This is the channel code according to the SEED standard.\n",
    "    code=\"HHZ\",\n",
    "    # This is the location code according to the SEED standard.\n",
    "    location_code=\"\",\n",
    "    # Note that these coordinates can differ from the station coordinates.\n",
    "    latitude=1.0,\n",
    "    longitude=2.0,\n",
    "    elevation=345.0,\n",
    "    depth=10.0,\n",
    "    azimuth=0.0,\n",
    "    dip=-90.0,\n",
    "    sample_rate=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next the tutorial pulls a station response file from the Nominal Response Library. This is a repository of instrument responses for commercial seismometers, but it's unlikely to be useful for lab sensors. I'll include it here for the sake of continuing to follow the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default this accesses the NRL online. Offline copies of the NRL can\n",
    "# also be used instead\n",
    "nrl = NRL()\n",
    "# The contents of the NRL can be explored interactively in a Python prompt,\n",
    "# see API documentation of NRL submodule:\n",
    "# http://docs.obspy.org/packages/obspy.clients.nrl.html\n",
    "# Here we assume that the end point of data logger and sensor are already known:\n",
    "response = nrl.get_response( # doctest: +SKIP\n",
    "    sensor_keys=['Streckeisen', 'STS-1', '360 seconds'],\n",
    "    datalogger_keys=['REF TEK', 'RT 130 & 130-SMA', '1', '200'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the objects we've created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cha.response = response\n",
    "sta.channels.append(cha)\n",
    "net.stations.append(sta)\n",
    "inv.networks.append(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally write it to a StationXML file. We also force a validation against the StationXML schema to ensure it produces a valid StationXML file. There's a note that \"it's also possible to serialize to any of the other inventory output formats ObsPy supports.\" I'm not sure what that means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv.write(\"test_station.xml\", format=\"stationxml\", validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning_ASDF.ipynb  test_station.xml\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QuakeML from scratch\n",
    "Next I need to figure out how to make a QuakeML file for a lab event. There is no tutorial I could find so we'll dig through the documentation. There's a quakeml package with a write function, `obspy.core.quakeml.writeQuakeML`, but it's doc has a big warning that it should only be used through the write function of an ObsPy `Catalog` object.\n",
    "\n",
    "The __[Catalog class](http://docs.obspy.org/packages/autogen/obspy.core.event.catalog.Catalog.html#obspy.core.event.catalog.Catalog)__ is just a container for __[Event objects](http://docs.obspy.org/packages/autogen/obspy.core.event.event.Event.html#obspy.core.event.event.Event)__. `Event` objects start to have actual info in them, although a bunch of it also goes into sub-classes like `Pick`, `Origin`, `Magnitude`, etc. I'll go ahead and try to create a fully populated `Event` with dummy info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import obspy\n",
    "import obspy.core.event as ev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be a lot of value in properly used __[ResourceIdentifier](https://docs.obspy.org/packages/autogen/obspy.core.event.base.ResourceIdentifier.html#obspy.core.event.base.ResourceIdentifier)__s. It seems like most of the referencing will be auto-generated. I'll try starting with a `ResourceIdentifier` for an event and filling in from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event:\t\n",
      "\n",
      " event/ed1c4557-361d-4087-ba7b-3cc5c2b03972\n"
     ]
    }
   ],
   "source": [
    "event = ev.Event()\n",
    "event.resource_id = ev.ResourceIdentifier(prefix='event', referred_object=event)\n",
    "print(event, event.resource_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's no laboraty event `EventType` so I'll use \"other event\" with \"known\" certainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Setting attribute \"event_type\" failed. Value \"other ev\" could not be converted to type \"Enum([\"not existing\", \"not reported\", \"earthquake\", ..., \"rockslide\", \"meteorite\", \"volcanic eruption\"])\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-e65c503f3628>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEventType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'other event'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent_type_certainty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEventTypeCertainty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'known'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'other ev'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/obspy/lib/python3.6/site-packages/obspy/core/event/base.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m    378\u001b[0m                     \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'Value \"%s\" could not be converted to type \"%s\"'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                         \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattrib_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Setting attribute \"event_type\" failed. Value \"other ev\" could not be converted to type \"Enum([\"not existing\", \"not reported\", \"earthquake\", ..., \"rockslide\", \"meteorite\", \"volcanic eruption\"])\""
     ]
    }
   ],
   "source": [
    "event.event_type = ev.header.EventType(enum='other event')\n",
    "event.event_type_certainty = ev.header.EventTypeCertainty(enum='known')\n",
    "event.event_type = 'other ev'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I noticed that the value actually stored for `event.event_type` was just the string 'other event', so I was curious if I could just assign a string instead of an `EventType` object. The error from trying to set 'other ev' shows that the `Event.event_type` parameter automatically invokes the `EventType` class and checks that the assigned string is in the enumerated list. A simple string assignment works with allowed value and produces exactly the same stored value as the object assignment I initially used.\n",
    "\n",
    "The next parameter (alphabetically) is `Event.creation_info`. A `CreationInfo` object can contain an `agency_id`, an `agency_uri`, an `author`, an `author_uri`, a `creation_time`, and a `version`. The two uri fields both take (or create if called with just a string?) `ResourceIdentifier` objects. I'll fill in some dummy info for completeness of this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreationInfo(author='JP', creation_time=UTCDateTime(2018, 2, 6, 23, 4, 51, 234891))\n"
     ]
    }
   ],
   "source": [
    "event.creation_info = ev.base.CreationInfo(author='JP', creation_time=obspy.core.UTCDateTime.utcnow())\n",
    "print(event.creation_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next is `Event.event_descriptions`, which can contain a list of `EventDescription` objects. Each of these contains a piece of descriptive text and an optional `EventDescriptionType` such as \"earthquake name\". The types are an extra bit of standardized metadata that could make filtering for events easier. I've tried adding a description but there is no automatic processing getting triggered. The assignment seems to be verbatim and the `event_descriptions` key doesn't show up as part of the `Event` dictionary. Something to come back to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EventDescription(text='a fake example event')]\n"
     ]
    }
   ],
   "source": [
    "event.event_descriptions = [ev.event.EventDescription(text='a fake example event')]\n",
    "print(event.event_descriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Event.comments` is another list field, although `Comment` objects can have a `ResourceIdentifier` and `CreationInfo`. \n",
    "\n",
    "The remaining parameters for an `Event` are `picks`, `amplitudes`, `focal_mechanisms`, `origins`, `magnitudes`, and `station_magnitudes`. All of these parameters have their own classes and are able to contain quite a lot of inter-related information. Filling these in will make much more sense with sample data. For now, I have a very empty `Event` that should be enough to write a very empty QuakeML file to use in my ASDF trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = ev.Catalog(creation_info=ev.base.CreationInfo(author='JP', creation_time=obspy.core.UTCDateTime.utcnow()))\n",
    "catalog.resource_id = ev.ResourceIdentifier(prefix='catalog', referred_object=catalog)\n",
    "catalog.append(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValuesView(Event(resource_id=ResourceIdentifier(id=\"event/ed1c4557-361d-4087-ba7b-3cc5c2b03972\"), event_type='other event', event_type_certainty='known', creation_info=CreationInfo(author='JP', creation_time=UTCDateTime(2018, 2, 6, 23, 4, 51, 234891))))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[EventDescription(text='a fake example event')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(event.values())\n",
    "event.event_descriptions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
