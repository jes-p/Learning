{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Waveforms\n",
    "Here we combine the experiment-specific stationXML file created in GLNN_StationXML.ipynb with the recorded AE waveforms from TranAX in a tpc5 file to initialize the experiment ASDF file.\n",
    "\n",
    "ElSys has provided a module tpc5.py __[available on their website](https://www.elsys-instruments.com/en/support/tpc5_fileformat.php)__ for easy interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tpc5 # get from ElSys, see link above\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pyasdf\n",
    "from obspy import Stream, Trace\n",
    "from obspy.core.util import AttribDict\n",
    "from obspy.core import Stats\n",
    "import obspy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First set up the ASDF dataset to fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pyasdf.ASDFDataSet('020918_shear/020918ASDF.h5', compression='gzip-3')\n",
    "ds.add_stationxml('020918_shear/GLNNstations_020918.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['L0.AE09',\n",
       " 'L0.AE11',\n",
       " 'L0.AE16',\n",
       " 'L0.AE17',\n",
       " 'L0.AE18',\n",
       " 'L0.AE21',\n",
       " 'L0.AE22',\n",
       " 'L0.AE23',\n",
       " 'L0.AE27',\n",
       " 'L0.AE28',\n",
       " 'L0.AE32',\n",
       " 'L0.AE33',\n",
       " 'L0.AE35',\n",
       " 'L0.AE38',\n",
       " 'L0.AE41',\n",
       " 'L0.AE43']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.waveforms.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Station AE09 (BP3)\n",
       "\tStation Code: AE09\n",
       "\tChannel Count: 1/None (Selected/Total)\n",
       "\tNone - \n",
       "\tAccess: None \n",
       "\tLatitude: 37.87, Longitude: -122.26, Elevation: 100.0 m\n",
       "\tAvailable Channels:\n",
       "\t\tAE09.00.FHZ"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.waveforms.L0_AE09.StationXML.networks[0].stations[0]\n",
    "# ASDF appears to dump the extra attribute of the StationXML\n",
    "# Add the (x,y) locations as auxiliary data instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stations are ordered as A1-D4 in the original StationXML but get re-sorted to increasing station codes when imported to ASDF. The ASDF format also drops the .extra attribute from the StationXML, which contained my local_location information. I need to temporarily access the StationXML outside of ASDF to bring back this lost information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv = obspy.read_inventory('020918_shear/GLNNstations_020918.xml', format='stationxml')\n",
    "ordered_stations = [inv.get_contents()['stations'][i][3:7] for i in range(16)]\n",
    "ordered_locations = [(float(inv[0].stations[i].extra.local_location.value['x'].value),\n",
    "                      float(inv[0].stations[i].extra.local_location.value['y'].value),\n",
    "                      float(inv[0].stations[i].extra.local_location.value['z'].value))\n",
    "                     for i in range(16)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AttribDict({'local_location': AttribDict({'namespace': 'GLNN', 'value': AttribDict({'x': AttribDict({'namespace': 'GLNN', 'value': '9.9568', 'attrib': {'unit': 'CENTIMETERS'}}), 'y': AttribDict({'namespace': 'GLNN', 'value': '19.05', 'attrib': {'unit': 'CENTIMETERS'}}), 'z': AttribDict({'namespace': 'GLNN', 'value': '0', 'attrib': {'unit': 'CENTIMETERS'}})})})})"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv[0].stations[3].extra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These bits of extra info are great candidates for ASDF auxiliary data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(9.9568, 19.05, 0.0),\n",
       " (9.9568, 19.05, 0.0),\n",
       " (9.9568, 19.05, 0.0),\n",
       " (9.9568, 19.05, 0.0),\n",
       " (9.9568, 19.05, 0.0),\n",
       " (9.9568, 19.05, 0.0),\n",
       " (9.9568, 19.05, 0.0),\n",
       " (9.9568, 19.05, 0.0),\n",
       " (9.9568, 19.05, 0.0),\n",
       " (9.9568, 19.05, 0.0),\n",
       " (9.9568, 19.05, 0.0),\n",
       " (9.9568, 19.05, 0.0),\n",
       " (9.9568, 19.05, 0.0),\n",
       " (9.9568, 19.05, 0.0),\n",
       " (9.9568, 19.05, 0.0),\n",
       " (9.9568, 19.05, 0.0)]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordered_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "No conversion path for dtype: dtype('<U4')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-181-7fa50028b5e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                       \u001b[0mdata_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'LabStationInfo'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                       \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'A1D4_order'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                       parameters={})\n\u001b[0m\u001b[1;32m      5\u001b[0m ds.add_auxiliary_data(data=np.array(ordered_locations),\n\u001b[1;32m      6\u001b[0m                       \u001b[0mdata_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'LabStationInfo'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/obspy/lib/python3.6/site-packages/pyasdf/asdf_data_set.py\u001b[0m in \u001b[0;36madd_auxiliary_data\u001b[0;34m(self, data, data_type, path, parameters, provenance_id)\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_auxiliary_data_write_collective_information\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m         self._add_auxiliary_data_write_independent_information(info=info,\n\u001b[1;32m    601\u001b[0m                                                                data=data)\n",
      "\u001b[0;32m~/anaconda3/envs/obspy/lib/python3.6/site-packages/pyasdf/asdf_data_set.py\u001b[0m in \u001b[0;36m_add_auxiliary_data_write_collective_information\u001b[0;34m(self, info)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_auxiliary_data_group\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m         \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dataset_creation_params\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dataset_attrs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/obspy/lib/python3.6/site-packages/h5py/_hl/group.py\u001b[0m in \u001b[0;36mcreate_dataset\u001b[0;34m(self, name, shape, dtype, data, **kwds)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \"\"\"\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0mdsid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_new_dset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m             \u001b[0mdset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/obspy/lib/python3.6/site-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36mmake_new_dset\u001b[0;34m(parent, shape, dtype, data, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mtid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy_create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogical\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;31m# Legacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/h5t.pyx\u001b[0m in \u001b[0;36mh5py.h5t.py_create\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5t.pyx\u001b[0m in \u001b[0;36mh5py.h5t.py_create\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5t.pyx\u001b[0m in \u001b[0;36mh5py.h5t.py_create\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: No conversion path for dtype: dtype('<U4')"
     ]
    }
   ],
   "source": [
    "ds.add_auxiliary_data(data=np.array(ordered_locations),\n",
    "                      data_type='LabStationInfo',\n",
    "                      path='local_locations',\n",
    "                      parameters={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now on to importing the waveforms. An experiment might be made up of multiple files. Display the tpc5 files present in the experiment folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "020918_shear/bd1.tpc5  020918_shear/run.tpc5\r\n",
      "020918_shear/bd2.tpc5  020918_shear/timing.tpc5\r\n"
     ]
    }
   ],
   "source": [
    "!ls 020918_shear/*.tpc5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This experiment had two ball drops (bd1, bd2), a timing alignment signal (timing), and the full shear run (run). I'll start with the first ball drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(\"020918_shear/run.tpc5\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to know how many blocks to read\n",
    "# all channels have the same number of blocks, use channel 1\n",
    "cg = f[tpc5.getChannelGroupName(1)]\n",
    "nblocks = len(cg['blocks'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the raw data from each channel into a stream, one trace at a time\n",
    "# first build some basic Stats\n",
    "statn_stats = Stats()\n",
    "statn_stats.network = 'L0'\n",
    "statn_stats.channel = 'FHZ'\n",
    "statn_stats.location = '00'\n",
    "statn_stats.sampling_rate = 20e6\n",
    "\n",
    "# make sure times will retain full precision\n",
    "# the ElSys max precision seems to be nanoseconds\n",
    "obspy.UTCDateTime.DEFAULT_PRECISION = 9\n",
    "\n",
    "# iterate through stations, following the ordered_stations A1-D4 sort\n",
    "# the number of the (ordered) station is the TranAX channel A1-D4->1-16, here Tchan\n",
    "for Tchan,statname in enumerate(ordered_stations,1):\n",
    "    # add the station to the stats\n",
    "    statn_stats.station = statname\n",
    "    \n",
    "    # create a stream for the station\n",
    "    statn_stream = Stream()\n",
    "    \n",
    "    # iterate through continuous data segments\n",
    "    # TranAX calls these Blocks, obspy calls them Traces\n",
    "    for blk in range(nblocks):\n",
    "        # get the trace start time\n",
    "        statn_stats.starttime = tpc5.getStartTime(f,1) \\ # gives the start of the whole recording\n",
    "                                + tpc5.getTrigger(f,1,block=blk) \\ # seconds from start to trigger\n",
    "                                - tpc5.getTriggerSample(f,1,block=blk)/statn_stats.sampling_rate # seconds from trigger to block start\n",
    "        \n",
    "        # add the trace of raw voltage data to the stream\n",
    "        statn_stream += Trace(tpc5.getVoltageData(f, Tchan, block=blk),statn_stats)\n",
    "    \n",
    "    # add the complete stream to the ASDF object\n",
    "    ds.add_waveforms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra notes\n",
    "Accessing tpc5 and hdf5 files can be a bit confusing. Here are some reminders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to view the keys of an hdf5 file:\n",
    "list(f.keys())\n",
    "\n",
    "# to then access one of the keys:\n",
    "f['key']\n",
    "\n",
    "# to control the precision of a UTCDateTime\n",
    "t = obspy.UTCDateTime(precision=9)\n",
    "# doing arithmetic creates a new UTCDateTime with the default precision!\n",
    "# change the default precision for the session\n",
    "obspy.UTCDateTime.DEFAULT_PRECISION = 9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
